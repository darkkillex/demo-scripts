CHECK THE VERSION OF ETCD

Look at the ETCD Logs using the command:
kubectl logs etcd-controlplane -n kube-system
or
check the image used by the ETCD pod:
kubectl describe pod etcd-controlplane -n kube-system
    Image:         k8s.gcr.io/etcd:3.5.1-0


AT WHAT ADDRESS CAN YOU REACH THE ETCD CLUSTER FROM THE CONTROLPLANE NODE?
describe the etcd-controlplane POD and check the line:
    --listen-client-urls=https://127.0.0.1:2379

WHERE IS THE ETCD SERVER CERTIFICATE FILE LOCATED?
describe the etcd-controlplane POD and check the line:
    --cert-file=/etc/kubernetes/pki/etcd/server.crt

WHERE IS THE ETCD CA CERTIFICATE FILE LOCATED?
describe the etcd-controlplane POD and check the line:
    --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt


BACK OF ETCD to /opt/snapshot-pre-boot.db
Use case: The master node in our cluster is planned for a regular maintenance reboot tonight.
While we do not anticipate anything to go wrong, we are required to take the necessary backups.
Take a snapshot of the ETCD database using the built-in snapshot functionality.
Store the backup file at location /opt/snapshot-pre-boot.db

Run the following command:

    ETCDCTL_API=3 etcdctl --endpoints=https://[127.0.0.1]:2379 \
    --cacert=/etc/kubernetes/pki/etcd/ca.crt \
    --cert=/etc/kubernetes/pki/etcd/server.crt \
    --key=/etc/kubernetes/pki/etcd/server.key \
    snapshot save /opt/snapshot-pre-boot.db

    """""
'ETCD_API=3 etcdctl snapshot save' command. You will have to make use of additional flags to connect to the ETCD server.
--endpoints: Optional Flag, points to the address where ETCD is running (127.0.0.1:2379)
--cacert: Mandatory Flag (Absolute Path to the CA certificate file)
--cert: Mandatory Flag (Absolute Path to the Server certificate file)
--key:Mandatory Flag (Absolute Path to the Key file)
"""""

RESTORE THE STATUS OF CLUSTER USING THE ETCD BACKUP (PREVOIUSLY DONE)

1. Stop 'service kube-apiserver stop'

2.Then Restore the snapshot:

  root@controlplane:~# ETCDCTL_API=3 etcdctl  --data-dir /var/lib/etcd-from-backup snapshot restore /opt/snapshot-pre-boot.db


  Note: In this case, we are restoring the snapshot to a different directory but in the same server
  where we took the backup (the controlplane node) As a result,
        the only required option for the restore command is the --data-dir.

  Next, update the /etc/kubernetes/manifests/etcd.yaml:

  We have now restored the etcd snapshot to a new path on the controlplane - /var/lib/etcd-from-backup, so,
  the only change to be made in the YAML file, is to change the hostPath for the volume called etcd-data
  from old directory (/var/lib/etcd) to the new directory /var/lib/etcd-from-backup.

    volumes:
    - hostPath:
        path: /var/lib/etcd-from-backup
        type: DirectoryOrCreate
      name: etcd-data

  With this change, /var/lib/etcd on the container points to /var/lib/etcd-from-backup on the controlplane
  (which is what we want)

  When this file is updated, the ETCD pod is automatically re-created as this is a static pod placed under the
  /etc/kubernetes/manifests directory.

  Note: as the ETCD pod has changed it will automatically restart, and also kube-controller-manager and kube-scheduler.
        Wait 1-2 to mins for this pods to restart. You can run a watch "docker ps | grep etcd" command to see when the
        ETCD pod is restarted.
  Note2: If the etcd pod is not getting Ready 1/1, then restart it by:
            kubectl delete pod -n kube-system etcd-controlplane
         and wait 1 minute.
  Note3: This is the simplest way to make sure that ETCD uses the restored data after the ETCD pod is recreated.
        You don't have to change anything else.

  If you do change --data-dir to /var/lib/etcd-from-backup in the YAML file, make sure that the volumeMounts
  for etcd-data is updated as well, with the mountPath pointing to /var/lib/etcd-from-backup
  (THIS COMPLETE STEP IS OPTIONAL AND NEED NOT BE DONE FOR COMPLETING THE RESTORE)


############    MORE THEORETICAL INFORMATION   #################################

Working with ETCDCTL

etcdctl is a command line client for etcd.
In all our Kubernetes Hands-on labs, the ETCD key-value database is deployed as a static pod on the master.
The version used is v3.
To make use of etcdctl for tasks such as back up and restore, make sure that you set the ETCDCTL_API to 3.
You can do this by exporting the variable ETCDCTL_API prior to using the etcdctl client. This can be done as follows:

export ETCDCTL_API=3

On the Master Node:
To see all the options for a specific sub-command, make use of the -h or --help flag.
For example, if you want to take a snapshot of etcd, use:
etcdctl snapshot save -h and keep a note of the mandatory global options.
Since our ETCD database is TLS-Enabled, the following options are mandatory:
--cacert                                                verify certificates of TLS-enabled secure servers using this CA bundle
--cert                                                    identify secure client using this TLS certificate file
--endpoints=[127.0.0.1:2379]          This is the default as ETCD is running on master node and exposed on localhost 2379.
--key                                                      identify secure client using this TLS key file

Similarly use the help option for snapshot restore to see all available options for restoring the backup.
etcdctl snapshot restore -h
For a detailed explanation on how to make use of the etcdctl command line tool and work with the -h flags,
check out the solution video for the Backup and Restore Lab.


